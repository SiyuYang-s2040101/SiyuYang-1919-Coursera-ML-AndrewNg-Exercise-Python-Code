{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Description\n",
    "## Linear regression with one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part of this exercise, you will implement linear regression with one variable to predict profits for a food truck. Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities. You would like to use this data to help you select which city to expand to next.\n",
    "- The file ex1data1.txt contains the dataset for our linear regression problem. The first column is the population of a city and the second column is the profit of a food truck in that city. A negative value for profit indicates a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Data from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from github\n",
    "# Remember to copy the link in the raw mode\n",
    "url = 'https://raw.githubusercontent.com/SiyuYang-1919/Coursera-ML-AndrewNg-Notes/master/code/ex1-linear%20regression/ex1data1.txt'\n",
    "data = pd.read_csv(url, delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = data.rename(columns={0:'Population(10k)', 1:'Profit($ 10k)'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=pp['Population(10k)'], y=pp['Profit($ 10k)'], c='cyan', marker='+')\n",
    "ax.set_xlabel('Population of City in 10,000s')\n",
    "ax.set_ylabel('Profit in $10,000s')\n",
    "ax.set_title('Population and Profit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preparation for the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to the dataset\n",
    "pp.insert(0, 'Ones', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fitting parameters\n",
    "theta = np.array([[0,0]])\n",
    "iterations = 1500\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compute the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cost function for the linear regrssion with one variable\n",
    "def CostFunction(m, theta, X, y):\n",
    "    j = sum((X.dot(np.transpose(theta)) - y)**2) / (2*m)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.mathwarehouse.com/algebra/matrix/multiply-matrix.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(pp.drop(['Profit($ 10k)'], axis=1))\n",
    "y = np.array(pd.DataFrame(pp['Profit($ 10k)']))\n",
    "m = pp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CostFunction(m=m, theta=theta, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the gradient descent function for one variable\n",
    "def GradientDescent(m, theta, X, y, alpha=0.01, iterations=1500):\n",
    "    # Update theta_j\n",
    "    for i in range(iterations):\n",
    "        differences = X.dot(theta.T) - y\n",
    "        x_1 = np.array(pd.DataFrame(X[:,1]))\n",
    "        theta_0 = theta[0][0] - alpha * sum(differences) / m\n",
    "        theta_1 = theta[0][1] - alpha * sum(differences.T.dot(x_1)) / m\n",
    "        theta = np.array([[theta_0[0], theta_1[0]]])\n",
    "        # Call the cost function to check if it is decreasing\n",
    "        # cost = CostFunction(m, theta, X, y)\n",
    "        # print(cost)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameters\n",
    "theta_new = GradientDescent(m=m, theta=theta, X=X, y=y, alpha=0.01, iterations=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction results\n",
    "predict1 = (np.array([[1, 3.5]])).dot(theta_new.T)\n",
    "predict2 = (np.array([[1, 7]])).dot(theta_new.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict1, predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the linear fit with computed parameters\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=pp['Population(10k)'], y=pp['Profit($ 10k)'], c='cyan', marker='+', label='Training data')\n",
    "x = pp['Population(10k)']\n",
    "y_1 = theta_new[0][0] + theta_new[0][1] * x\n",
    "ax.plot(pp['Population(10k)'], y_1, 'r-', label='Linear regression')\n",
    "ax.set_xlabel('Population of City in 10,000s')\n",
    "ax.set_ylabel('Profit in $10,000s')\n",
    "ax.set_title('Population and Profit')\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing the cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for plotting\n",
    "# The following code is modified according to the Octave code and figures provided in the exercise description\n",
    "size = 100\n",
    "m = pp.shape[0]\n",
    "X = np.array(pp.drop(['Profit($ 10k)'], axis=1))\n",
    "y = np.array(pd.DataFrame(pp['Profit($ 10k)']))\n",
    "\n",
    "theta0 = np.linspace(-10,10, size)\n",
    "theta1 = np.linspace(-2, 4, size)\n",
    "J = np.zeros((size, size))\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        col = np.array([[theta0[i], theta1[j]]])\n",
    "        J[i,j] = CostFunction(m, col, X, y)\n",
    "\n",
    "theta0_g, theta1_g = np.meshgrid(theta0, theta1)\n",
    "J = J.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the 3D surface plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.plot_surface(theta0_g, theta1_g, J, rstride=2, cstride=2, alpha=0.3,\n",
    "                cmap=cm.rainbow, linewidth=0, antialiased=False)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('thet0')\n",
    "ax.set_ylabel('theta1')\n",
    "ax.set_zlabel('J')\n",
    "\n",
    "# Adjust the format of z-axis\n",
    "ax.set_zlim(np.min(J), np.max(J))\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "\n",
    "# Ajust the format of values in each axis\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.01f'))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.01f'))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.01f'))\n",
    "\n",
    "# Add a colorbar\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('Cost Function 3D', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the contour plot\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax1.set_xlabel('theta_0')\n",
    "ax1.set_ylabel('theta_1')\n",
    "CS = ax1.contour(theta0_g, theta1_g, J, np.logspace(0, 3, 20))\n",
    "ax1.clabel(CS, inline=1, fontsize=5)\n",
    "ax1.scatter(x=theta_new[0][0], y=theta_new[0][1], c='red', marker='+')\n",
    "plt.savefig('Cost Function Contour', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- https://blog.csdn.net/Mr_Cat123/article/details/80677525?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\n",
    "- https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.contour.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualizing the gradient process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the cost function and gradient descent to get all the data in the minimization process\n",
    "def combined(m, theta, X, y, alpha=0.01, iterations=1500):\n",
    "    # Create empty lists to store the data\n",
    "    theta_0_s = []\n",
    "    theta_1_s = []\n",
    "    costs = []\n",
    "    for i in range(iterations):\n",
    "        # Fill the initialized/updated values\n",
    "        theta_0_s.append(theta[0][0])\n",
    "        theta_1_s.append(theta[0][1])\n",
    "        costs.append(CostFunction(m, theta, X, y)[0])\n",
    "        # Update theta_j\n",
    "        differences = X.dot(theta.T) - y\n",
    "        x_1 = np.array(pd.DataFrame(X[:,1]))\n",
    "        theta_0 = theta[0][0] - alpha * sum(differences) / m\n",
    "        theta_1 = theta[0][1] - alpha * sum(differences.T.dot(x_1)) / m\n",
    "        theta = np.array([[theta_0[0], theta_1[0]]])\n",
    "    # Fill the data in a single dataframe\n",
    "    d = {'theta_0': theta_0_s, 'theta_1': theta_1_s, 'cost': costs}\n",
    "    cost_data = pd.DataFrame(data=d)\n",
    "    return cost_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = combined(m=m, theta=theta, X=X, y=y, alpha=0.01, iterations=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for plotting\n",
    "# The following code will cost about 5min to run as there are 1500 iterations to finish\n",
    "length = costs.shape[0]\n",
    "cost = np.zeros((length, length))\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        theta = np.array([[costs['theta_0'][i], costs['theta_1'][j]]])\n",
    "        cost[i,j] = CostFunction(m, theta, X, y)\n",
    "\n",
    "theta_0 = np.array(costs['theta_0'])\n",
    "theta_1 = np.array(costs['theta_1'])\n",
    "theta_0_g, theta_1_g = np.meshgrid(theta_0, theta_1)\n",
    "cost = cost.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the 3D plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.plot_surface(theta_0_g, theta_1_g, cost, rstride=2, cstride=2, alpha=0.3,\n",
    "                cmap=cm.rainbow, linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_xlabel('theta_0')\n",
    "ax.set_ylabel('theta_1')\n",
    "ax.set_zlabel('cost')\n",
    "\n",
    "ax.set_zlim(np.min(cost), np.max(cost))\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.01f'))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.01f'))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.01f'))\n",
    "\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.savefig('Gradient Descent 3D', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the contour plot with the path of optimization\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.set_xlabel('theta_0')\n",
    "ax2.set_ylabel('theta_1')\n",
    "CS = ax2.contour(theta_0_g, theta_1_g, cost, np.logspace(0, 2, 20))\n",
    "ax2.clabel(CS, inline=1, fontsize=10)\n",
    "ax2.scatter(x=theta_new[0][0], y=theta_new[0][1], c='red', marker='+')\n",
    "ax2.scatter(x=costs['theta_0'], y=costs['theta_1'], s=0.1, c='dodgerblue', marker='.')\n",
    "plt.savefig('Gradient Descent Contour', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence of gradient descent\n",
    "# Exclude the first value of theta_0, theta_1, and cost\n",
    "x = np.arange(1, iterations)\n",
    "y = costs['cost'][1:]\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "ax3.plot(x, y, 'r-')\n",
    "ax3.set_xlabel('Iterations')\n",
    "ax3.set_ylabel('Costs')\n",
    "plt.savefig('Convergence of Gradient Descent', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Multiple Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part, you will implement linear regression with multiple variables to predict the prices of houses. Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to first collect information on recent houses sold and make a model of housing\n",
    "prices. \n",
    "- The \f",
    "file ex1data2.txt contains a training set of housing prices in Portland, Oregon. The \f",
    "first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price\n",
    "of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Data from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://raw.githubusercontent.com/SiyuYang-1919/Coursera-ML-AndrewNg-Notes/master/code/ex1-linear%20regression/ex1data2.txt'\n",
    "data1 = pd.read_csv(url1, delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmv = data1.rename(columns={0: 'House size(square feet)', 1: 'Bedroom number', 2: 'House Price'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# House size\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=lrmv['House size(square feet)'], y=lrmv['House Price'], c='dodgerblue', marker='x')\n",
    "ax.set_xlabel('House size')\n",
    "ax.set_ylabel('House Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedroom number\n",
    "lrmv['Bedroom number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(lrmv['Bedroom number'], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], color='dodgerblue')\n",
    "ax.set_title('Bedroom number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=lrmv['Bedroom number'], y=lrmv['House Price'], c='dodgerblue', marker='x')\n",
    "ax.set_xlabel('Bedroom number')\n",
    "ax.set_ylabel('House Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureNormalization(values):\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    values_fn = (values - mean) / std\n",
    "    return round(mean,2), round(std,2), np.round(values_fn,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hs, std_hs, lrmv['House size(square feet)']= FeatureNormalization(lrmv['House size(square feet)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bn, std_bn, lrmv['Bedroom number']= FeatureNormalization(lrmv['Bedroom number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmv.insert(0, 'Ones', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modified Cost Function and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cost when theta is initilized\n",
    "m1 = lrmv.shape[0]\n",
    "theta1 = np.array([[0, 0, 0]])\n",
    "X1 = np.array(lrmv.drop(['House Price'], axis=1))\n",
    "y1 = np.array(pd.DataFrame(lrmv['House Price']))\n",
    "CostFunction(m=m1, theta=theta1, X=X1, y=y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modify the gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a new gradient descent function for multiple variables\n",
    "def GradientDescent(m, theta, X, y, alpha=0.01, iterations=1500):\n",
    "    # Update theta_j\n",
    "    for i in range(iterations):\n",
    "        differences = X.dot(theta.T) - y\n",
    "        theta_values = []\n",
    "        for n in range(X.shape[1]):\n",
    "            x = np.array(pd.DataFrame(X[:,n]))\n",
    "            theta_value = theta[0][n] - alpha * sum(differences.T.dot(x)) / m\n",
    "            theta_values.append(theta_value[0])\n",
    "        theta = np.array([theta_values])\n",
    "        # Call the cost function to check if it is decreasing\n",
    "        # cost = CostFunction(m, theta, X, y)\n",
    "        # print(cost)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "m1 = lrmv.shape[0]\n",
    "theta1 = np.array([[0, 0, 0]])\n",
    "X1 = np.array(lrmv.drop(['House Price'], axis=1))\n",
    "y1 = np.array(pd.DataFrame(lrmv['House Price']))\n",
    "GradientDescent(m=m1, theta=theta1, X=X1, y=y1, alpha=0.01, iterations=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modify the combined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified combined function\n",
    "def combined(m, theta, X, y, alpha=0.01, iterations=1500, plot=True):\n",
    "    # Create empty lists to store the data\n",
    "    data_store = np.zeros((iterations, X.shape[1]+1))\n",
    "    for i in range(iterations):\n",
    "        data_store[i][X.shape[1]] = CostFunction(m, theta, X, y)\n",
    "        differences = X.dot(theta.T) - y\n",
    "        theta_values = []\n",
    "        for n in range(X.shape[1]):\n",
    "            x = np.array(pd.DataFrame(X[:,n]))\n",
    "            theta_value = theta[0][n] - alpha * sum(differences.T.dot(x)) / m\n",
    "            data_store[i][n] = theta_value\n",
    "            theta_values.append(theta_value[0])\n",
    "        theta = np.array([theta_values])\n",
    "    # Fill the data in a single dataframe\n",
    "    cost_data = pd.DataFrame(data_store)\n",
    "    if plot:\n",
    "        x = np.arange(0, 50)\n",
    "        y = cost_data.iloc[0:50, 3]\n",
    "        fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "        ax3.plot(x, y, 'r-')\n",
    "        ax3.set_xlabel('Number of Iterations')\n",
    "        ax3.set_ylabel('Cost J')\n",
    "        ax3.set_title('Convergence of Gradient Descent')\n",
    "    return cost_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "costs = combined(m=m1, theta=theta1, X=X1, y=y1, alpha=0.1, iterations=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Selecting learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs1 = combined(m=m1, theta=theta1, X=X1, y=y1, alpha=0.3, iterations=50, plot=False)\n",
    "costs2 = combined(m=m1, theta=theta1, X=X1, y=y1, alpha=0.1, iterations=50, plot=False)\n",
    "costs3 = combined(m=m1, theta=theta1, X=X1, y=y1, alpha=0.03, iterations=50, plot=False)\n",
    "costs4 = combined(m=m1, theta=theta1, X=X1, y=y1, alpha=0.01, iterations=50, plot=False)\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(0, 50)\n",
    "costs_data = [costs1, costs2, costs3, costs4]\n",
    "line_type = ['r-', 'g--', 'b-.', 'k.']\n",
    "alpha = [0.3, 0.1, 0.03, 0.01]\n",
    "for i in range(0, 4):\n",
    "    y = costs_data[i][3]\n",
    "    ax3.plot(x, y, line_type[i], label='alpha='+str(alpha[i]))\n",
    "    ax3.set_xlabel('Number of Iterations')\n",
    "    ax3.set_ylabel('Cost J')\n",
    "    ax3.set_title('Convergence of Gradient Descent')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Choose parameters and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above section, we can see that the combination of alpha=0.1 and iterations=1500 is quite reasonable\n",
    "theta_model = GradientDescent(m=m1, theta=theta1, X=X1, y=y1, alpha=0.1, iterations=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the parameters\n",
    "p1 = (1650 - mean_hs) / std_hs\n",
    "p2 = (3 - mean_bn) / std_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction\n",
    "price_predicted = np.array([[1, p1, p2]]).dot(theta_model.T)\n",
    "price_gd = round(price_predicted[0][0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalEquations(X, y):\n",
    "    inner = np.linalg.inv((X.T @ X))\n",
    "    next = inner @ X.T\n",
    "    theta = next @ y\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(lrmv.drop(['House Price'], axis=1))\n",
    "y1 = np.array(pd.DataFrame(lrmv['House Price']))\n",
    "theta = NormalEquations(X=X1, y=y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "price_predicted_ne = np.array([[1, p1, p2]]).dot(theta)\n",
    "price_ne = round(price_predicted_ne[0][0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between two predictions\n",
    "difference = price_gd - price_ne\n",
    "round(difference, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
